{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T00:59:48.364912Z",
     "iopub.status.busy": "2025-11-08T00:59:48.364201Z",
     "iopub.status.idle": "2025-11-08T00:59:52.178518Z",
     "shell.execute_reply": "2025-11-08T00:59:52.177631Z",
     "shell.execute_reply.started": "2025-11-08T00:59:48.364884Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q wurlitzer ninja\n",
    "%load_ext wurlitzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T00:59:52.180283Z",
     "iopub.status.busy": "2025-11-08T00:59:52.180071Z",
     "iopub.status.idle": "2025-11-08T00:59:59.180613Z",
     "shell.execute_reply": "2025-11-08T00:59:59.180058Z",
     "shell.execute_reply.started": "2025-11-08T00:59:52.180260Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7a1216646f90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.cpp_extension import load_inline\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "device = \"cuda\"\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv + Relu Fused Py Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T00:59:59.181534Z",
     "iopub.status.busy": "2025-11-08T00:59:59.181269Z",
     "iopub.status.idle": "2025-11-08T00:59:59.186454Z",
     "shell.execute_reply": "2025-11-08T00:59:59.185831Z",
     "shell.execute_reply.started": "2025-11-08T00:59:59.181510Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def run_kernel(f, times, *args):\n",
    "    for i in range(times):\n",
    "        f(i, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T00:59:59.188488Z",
     "iopub.status.busy": "2025-11-08T00:59:59.188226Z",
     "iopub.status.idle": "2025-11-08T00:59:59.204416Z",
     "shell.execute_reply": "2025-11-08T00:59:59.203734Z",
     "shell.execute_reply.started": "2025-11-08T00:59:59.188465Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# üîπ Description:\n",
    "# This function is supposed to perform a 3x3 convolution on each pixel of the input image\n",
    "# and then apply the ReLU activation function to the result.\n",
    "#\n",
    "# In other words, this is the \"kernel\" part ‚Äî where the actual multiply‚Äìaccumulate\n",
    "# operations of convolution happen.\n",
    "#\n",
    "# Parameters:\n",
    "# - i : the index of the pixel (from 0 to N*H*W - 1)\n",
    "# - x : the input tensor of shape [N, 1, H, W]\n",
    "# - w : the convolution filter (weights) of shape [1, 1, 3, 3]\n",
    "# - b : the bias term (a scalar tensor)\n",
    "# - out : the output tensor to store results\n",
    "# - N, H, W : dimensions of the input (batch size, height, width)\n",
    "#\n",
    "# Inside this function, students should:\n",
    "# 1Ô∏è Convert i into (n, h, w) indices ‚Äî to locate the correct pixel in the batch\n",
    "# 2Ô∏è Compute the accumulated sum (acc) by multiplying the 3x3 neighborhood by the weights\n",
    "# 3Ô∏è Add the bias term b\n",
    "# 4Ô∏è Apply ReLU (if acc < 0, set it to 0)\n",
    "# 5Ô∏è Store the result in out[n, 0, h, w]\n",
    "\n",
    "def conv_relu_kernel_py(i, x, w, b, out, N, H, W):\n",
    "    pass  # you should write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T00:59:59.205439Z",
     "iopub.status.busy": "2025-11-08T00:59:59.205200Z",
     "iopub.status.idle": "2025-11-08T00:59:59.214596Z",
     "shell.execute_reply": "2025-11-08T00:59:59.214060Z",
     "shell.execute_reply.started": "2025-11-08T00:59:59.205417Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function: conv_relu_py\n",
    "# ----------------------\n",
    "# üîπ Description:\n",
    "# This is the higher-level wrapper function that coordinates the operation.\n",
    "# It:\n",
    "# 1Ô∏è Checks that the input tensors have the expected shapes (using assert)\n",
    "# 2Ô∏è Creates an output tensor with the same size as x\n",
    "# 3Ô∏è Calls the run_kernel function, which runs conv_relu_kernel_py\n",
    "#     for each pixel index i (from 0 to N*H*W)\n",
    "# 4Ô∏è Returns the output tensor\n",
    "#\n",
    "# So, this function organizes and launches the lower-level computation.\n",
    "def conv_relu_py(x, w, b):\n",
    "    pass  # you should write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T00:59:59.215694Z",
     "iopub.status.busy": "2025-11-08T00:59:59.215352Z",
     "iopub.status.idle": "2025-11-08T00:59:59.333057Z",
     "shell.execute_reply": "2025-11-08T00:59:59.332367Z",
     "shell.execute_reply.started": "2025-11-08T00:59:59.215653Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = \"cpu\"  \n",
    "\n",
    "H, W = 8, 8  \n",
    "\n",
    "x = torch.randn(4, 1, H, W, device=device)\n",
    "\n",
    "conv = torch.nn.Conv2d(1, 1, kernel_size=3, padding=1, bias=True).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    conv.weight.copy_(torch.randn_like(conv.weight))\n",
    "    conv.bias.copy_(torch.randn_like(conv.bias))\n",
    "\n",
    "w = conv.weight.detach()\n",
    "b = conv.bias.detach()\n",
    "\n",
    "y_ref = F.relu(conv(x))\n",
    "\n",
    "y_py = conv_relu_py(x, w, b)\n",
    "\n",
    "print(\"Max diff:\", (y_ref - y_py).abs().max().item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cuda Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T00:59:59.334294Z",
     "iopub.status.busy": "2025-11-08T00:59:59.333851Z",
     "iopub.status.idle": "2025-11-08T01:00:59.817689Z",
     "shell.execute_reply": "2025-11-08T01:00:59.816875Z",
     "shell.execute_reply.started": "2025-11-08T00:59:59.334267Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cuda_begin = r'''\n",
    "#include <torch/extension.h>\n",
    "#include <c10/cuda/CUDAException.h>\n",
    "\n",
    "#define CHECK_CUDA(x) TORCH_CHECK(x.device().is_cuda(), #x \" must be a CUDA tensor\")\n",
    "#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\")\n",
    "#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
    "\n",
    "inline unsigned int cdiv(unsigned int a, unsigned int b) { return (a + b - 1) / b;}\n",
    "'''\n",
    "\n",
    "cuda_src = cuda_begin + r'''\n",
    "\n",
    "__global__ void conv_relu_kernel(\n",
    "    const float* __restrict__ x,\n",
    "    const float* __restrict__ w,\n",
    "    const float* __restrict__ b,\n",
    "    float* __restrict__ out,\n",
    "    int N,\n",
    "    int H,\n",
    "    int W\n",
    ") {\n",
    "\n",
    "    // You should write your code here\n",
    "\n",
    "}\n",
    "\n",
    "torch::Tensor conv_relu_fused(torch::Tensor x,\n",
    "                              torch::Tensor w,\n",
    "                              torch::Tensor b) {\n",
    "    CHECK_INPUT(x);\n",
    "    CHECK_INPUT(w);\n",
    "    CHECK_INPUT(b);\n",
    "\n",
    "    TORCH_CHECK(x.dim() == 4, \"x must be [N,C,H,W]\");\n",
    "    TORCH_CHECK(w.dim() == 4, \"w must be [C_out,C_in,3,3]\");\n",
    "    TORCH_CHECK(b.dim() == 1, \"b must be [C_out]\");\n",
    "\n",
    "    TORCH_CHECK(x.size(1) == 1, \"only C_in=1 supported\");\n",
    "    TORCH_CHECK(w.size(0) == 1 && w.size(1) == 1 &&\n",
    "                w.size(2) == 3 && w.size(3) == 3,\n",
    "                \"only 1x1x3x3 kernel supported\");\n",
    "    TORCH_CHECK(b.size(0) == 1, \"only 1 output channel supported\");\n",
    "\n",
    "    auto x_c = x.contiguous();\n",
    "    auto w_c = w.contiguous();\n",
    "    auto b_c = b.contiguous();\n",
    "\n",
    "    int N = x_c.size(0);\n",
    "    int H = x_c.size(2);\n",
    "    int W = x_c.size(3);\n",
    "\n",
    "    auto out = torch::empty_like(x_c);\n",
    "\n",
    "    int n_pix = N * H * W;\n",
    "    int threads = 256;\n",
    "    int blocks = cdiv(n_pix, threads);\n",
    "\n",
    "    conv_relu_kernel<<<blocks, threads>>>(\n",
    "        x_c.data_ptr<float>(),\n",
    "        w_c.data_ptr<float>(),\n",
    "        b_c.data_ptr<float>(),\n",
    "        out.data_ptr<float>(),\n",
    "        N, H, W\n",
    "    );\n",
    "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
    "\n",
    "    return out;\n",
    "}\n",
    "'''\n",
    "\n",
    "cpp_src = r'''\n",
    "torch::Tensor conv_relu_fused(torch::Tensor x,\n",
    "                              torch::Tensor w,\n",
    "                              torch::Tensor b);\n",
    "'''\n",
    "\n",
    "module = load_inline(\n",
    "    name=\"conv_relu_fused_ext\",\n",
    "    cpp_sources=[cpp_src],\n",
    "    cuda_sources=[cuda_src],\n",
    "    functions=[\"conv_relu_fused\"],\n",
    "    extra_cuda_cflags=[\"-O3\"],\n",
    "    verbose=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T01:00:59.819008Z",
     "iopub.status.busy": "2025-11-08T01:00:59.818563Z",
     "iopub.status.idle": "2025-11-08T01:00:59.827045Z",
     "shell.execute_reply": "2025-11-08T01:00:59.826284Z",
     "shell.execute_reply.started": "2025-11-08T01:00:59.818980Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FusedConvReLUFn(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, x, weight, bias):\n",
    "\n",
    "        assert x.is_cuda and weight.is_cuda and bias.is_cuda\n",
    "        assert x.dim() == 4 and x.size(1) == 1, \"only C_in=1 supported\"\n",
    "        assert weight.shape == (1, 1, 3, 3), \"only 1x1x3x3 kernel supported\"\n",
    "        assert bias.shape == (1,), \"only 1 output channel supported\"\n",
    "\n",
    "        y = module.conv_relu_fused(x, weight, bias)\n",
    "        ctx.save_for_backward(x, weight, bias, y)\n",
    "        return y\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        x, weight, bias, y = ctx.saved_tensors\n",
    "\n",
    "        # grad ReLU\n",
    "        mask = (y > 0).to(grad_output.dtype)\n",
    "        grad_z = grad_output * mask\n",
    "\n",
    "        # dL/dx\n",
    "        grad_x = torch.nn.grad.conv2d_input(\n",
    "            x.shape, weight, grad_z, padding=1\n",
    "        )\n",
    "        # dL/dW\n",
    "        grad_weight = torch.nn.grad.conv2d_weight(\n",
    "            x, weight.shape, grad_z, padding=1\n",
    "        )\n",
    "        # dL/db\n",
    "        grad_bias = grad_z.sum(dim=[0, 2, 3])\n",
    "\n",
    "        return grad_x, grad_weight, grad_bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T01:00:59.828468Z",
     "iopub.status.busy": "2025-11-08T01:00:59.827898Z",
     "iopub.status.idle": "2025-11-08T01:00:59.843022Z",
     "shell.execute_reply": "2025-11-08T01:00:59.842369Z",
     "shell.execute_reply.started": "2025-11-08T01:00:59.828449Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FusedConvReLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(1, 1, 3, 3))\n",
    "        self.bias   = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return FusedConvReLUFn.apply(x, self.weight, self.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T01:00:59.845608Z",
     "iopub.status.busy": "2025-11-08T01:00:59.845348Z",
     "iopub.status.idle": "2025-11-08T01:00:59.854579Z",
     "shell.execute_reply": "2025-11-08T01:00:59.853856Z",
     "shell.execute_reply.started": "2025-11-08T01:00:59.845592Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CNNBaseline(nn.Module):\n",
    "    def __init__(self, num_convs=5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_convs = num_convs\n",
    "        self.conv = nn.Conv2d(1, 1, kernel_size=3, padding=1, bias=True)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(14*14, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        for _ in range(self.num_convs):\n",
    "            x = F.relu(self.conv(x))\n",
    "        \n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T01:00:59.855746Z",
     "iopub.status.busy": "2025-11-08T01:00:59.855402Z",
     "iopub.status.idle": "2025-11-08T01:00:59.864607Z",
     "shell.execute_reply": "2025-11-08T01:00:59.864047Z",
     "shell.execute_reply.started": "2025-11-08T01:00:59.855724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CNNFused(nn.Module):\n",
    "    def __init__(self, num_convs=5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_convs = num_convs\n",
    "        self.conv = FusedConvReLU()\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(14*14, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        for _ in range(self.num_convs):\n",
    "            x = self.conv(x)\n",
    "        \n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T01:00:59.865748Z",
     "iopub.status.busy": "2025-11-08T01:00:59.865284Z",
     "iopub.status.idle": "2025-11-08T01:01:02.075627Z",
     "shell.execute_reply": "2025-11-08T01:01:02.074851Z",
     "shell.execute_reply.started": "2025-11-08T01:00:59.865724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_ds = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_ds  = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "test_loader  = torch.utils.data.DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T01:01:02.076951Z",
     "iopub.status.busy": "2025-11-08T01:01:02.076566Z",
     "iopub.status.idle": "2025-11-08T01:01:02.082696Z",
     "shell.execute_reply": "2025-11-08T01:01:02.081949Z",
     "shell.execute_reply.started": "2025-11-08T01:01:02.076925Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T01:01:02.083773Z",
     "iopub.status.busy": "2025-11-08T01:01:02.083501Z",
     "iopub.status.idle": "2025-11-08T01:01:02.098211Z",
     "shell.execute_reply": "2025-11-08T01:01:02.097580Z",
     "shell.execute_reply.started": "2025-11-08T01:01:02.083751Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model_timed(model, train_loader, test_loader, device, epochs=3, lr=1e-3):\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    epoch_total_times   = []\n",
    "    epoch_forward_times = []\n",
    "    epoch_backward_times= []\n",
    "    epoch_other_times   = []\n",
    "    test_accuracies     = []\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        fwd_time = 0.0\n",
    "        bwd_time = 0.0\n",
    "        other_time = 0.0\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            step_start = time.time()\n",
    "\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            # ----- forward -----\n",
    "            torch.cuda.synchronize()\n",
    "            t0 = time.time()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            torch.cuda.synchronize()\n",
    "            t1 = time.time()\n",
    "            fwd_time += (t1 - t0)\n",
    "\n",
    "            # ----- backward -----\n",
    "            torch.cuda.synchronize()\n",
    "            t2 = time.time()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.cuda.synchronize()\n",
    "            t3 = time.time()\n",
    "            bwd_time += (t3 - t2)\n",
    "\n",
    "            # ----- optimizer step -----\n",
    "            torch.cuda.synchronize()\n",
    "            t4 = time.time()\n",
    "            optimizer.step()\n",
    "            torch.cuda.synchronize()\n",
    "            t5 = time.time()\n",
    "            other_time += (t5 - t4)\n",
    "\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        epoch_end = time.time()\n",
    "        epoch_time = epoch_end - epoch_start\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader.dataset)\n",
    "        acc = evaluate(model, test_loader, device)\n",
    "\n",
    "        epoch_total_times.append(epoch_time)\n",
    "        epoch_forward_times.append(fwd_time)\n",
    "        epoch_backward_times.append(bwd_time)\n",
    "        epoch_other_times.append(other_time)\n",
    "        test_accuracies.append(acc)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch}: \"\n",
    "            f\"loss={avg_loss:.4f}, \"\n",
    "            f\"test_acc={acc*100:.2f}%, \"\n",
    "            f\"time_total={epoch_time:.2f}s \"\n",
    "            f\"(fwd={fwd_time:.2f}s, bwd={bwd_time:.2f}s, other={other_time:.2f}s)\"\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"total_times\": epoch_total_times,\n",
    "        \"forward_times\": epoch_forward_times,\n",
    "        \"backward_times\": epoch_backward_times,\n",
    "        \"other_times\": epoch_other_times,\n",
    "        \"test_accuracies\": test_accuracies,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T01:01:02.098939Z",
     "iopub.status.busy": "2025-11-08T01:01:02.098765Z",
     "iopub.status.idle": "2025-11-08T01:01:02.114346Z",
     "shell.execute_reply": "2025-11-08T01:01:02.113717Z",
     "shell.execute_reply.started": "2025-11-08T01:01:02.098926Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_convs = 2 # 2 and 10 should be tested\n",
    "\n",
    "baseline_cudnn = CNNBaseline(num_convs).to(device)\n",
    "baseline_cudnn_off = CNNBaseline(num_convs).to(device)\n",
    "baseline_cpu = CNNBaseline(num_convs).to(device)\n",
    "fused = CNNFused(num_convs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T01:01:02.115258Z",
     "iopub.status.busy": "2025-11-08T01:01:02.115006Z",
     "iopub.status.idle": "2025-11-08T01:01:02.126137Z",
     "shell.execute_reply": "2025-11-08T01:01:02.125494Z",
     "shell.execute_reply.started": "2025-11-08T01:01:02.115234Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def copy_weights(dst, src):\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        dst.conv.weight.copy_(src.conv.weight)\n",
    "        dst.conv.bias.copy_(src.conv.bias)\n",
    "        dst.fc1.weight.copy_(src.fc1.weight)\n",
    "        dst.fc1.bias.copy_(src.fc1.bias)\n",
    "        dst.fc2.weight.copy_(src.fc2.weight)\n",
    "        dst.fc2.bias.copy_(src.fc2.bias)\n",
    "\n",
    "copy_weights(fused, baseline_cudnn)\n",
    "copy_weights(baseline_cudnn_off, baseline_cudnn)\n",
    "copy_weights(baseline_cpu, baseline_cudnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T01:01:02.127134Z",
     "iopub.status.busy": "2025-11-08T01:01:02.126903Z",
     "iopub.status.idle": "2025-11-08T01:02:02.595527Z",
     "shell.execute_reply": "2025-11-08T01:02:02.594623Z",
     "shell.execute_reply.started": "2025-11-08T01:01:02.127114Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"=== Training baseline CNN (Conv2d + ReLU) - cuDNN  ===\")\n",
    "device = \"cuda\"\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "stats_base1 = train_model_timed(baseline_cudnn, train_loader, test_loader, device, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T01:02:02.597213Z",
     "iopub.status.busy": "2025-11-08T01:02:02.596925Z",
     "iopub.status.idle": "2025-11-08T01:02:33.215730Z",
     "shell.execute_reply": "2025-11-08T01:02:33.214791Z",
     "shell.execute_reply.started": "2025-11-08T01:02:02.597182Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n=== Training fused CNN (FusedConvReLU) ===\")\n",
    "\n",
    "stats_fused = train_model_timed(fused, train_loader, test_loader, device, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T01:02:33.217230Z",
     "iopub.status.busy": "2025-11-08T01:02:33.216942Z",
     "iopub.status.idle": "2025-11-08T01:03:52.072549Z",
     "shell.execute_reply": "2025-11-08T01:03:52.071808Z",
     "shell.execute_reply.started": "2025-11-08T01:02:33.217194Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"=== Training baseline CNN (Conv2d + ReLU) - cuDNN off ===\")\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "stats_base2 = train_model_timed(baseline_cudnn_off, train_loader, test_loader, device, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T01:03:52.074140Z",
     "iopub.status.busy": "2025-11-08T01:03:52.073634Z",
     "iopub.status.idle": "2025-11-08T01:04:32.014747Z",
     "shell.execute_reply": "2025-11-08T01:04:32.014004Z",
     "shell.execute_reply.started": "2025-11-08T01:03:52.074112Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"=== Training baseline CNN (Conv2d + ReLU) - CPU ===\")\n",
    "device = \"cpu\"\n",
    "\n",
    "stats_base3 = train_model_timed(baseline_cpu, train_loader, test_loader, device, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "crawling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
